wandb:
  project: default
  name: ''
  enable: False

debug: false
runs: 1
losstype: l1
ckpt: true

conv: ginconv
hidden: 192
num_conv_layers: 5
num_pred_layers: 1
num_mlp_layers: 1
num_backbone_mlp: 2
norm: graphnorm

finetune:
  lr: 1.e-3
  weight_decay: 0.
  epoch: 1000
  patience: 100
  batchsize: 128
  train_frac: 0.01
  modelpath: null
  whole: true
  num_mlp_layers: 1  # only when not tune the whole model

pretrain:
  lr: 1.e-3
  weight_decay: 0.
  epoch: 200
  patience: 50
  batchsize: 256
  subset: True
  drop_rate: 0.1
  temperature: 0.1
  num_pred_layers: 0  # no projector